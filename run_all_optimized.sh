#!/bin/bash
set -euo pipefail

cd ~/git/video-automation || { echo "‚ùå Failed to cd into ~/git/video-automation"; exit 1; }






echo "‚ñ∂Ô∏è Copy: audio / dashcam / bodycam"
./audio_copy.sh        || echo "‚ùå Failed: audio_copy.sh"
./dashcam_copy.sh      || echo "‚ùå Failed: dashcam_copy.sh"
./bodycam_copy.sh      || echo "‚ùå Failed: bodycam_copy.sh"

echo "‚ñ∂Ô∏è Whisper (chunked, merged, large-v3) over AUDIO tree"
# ./.venv/bin/python3 whisper_audio_chunked.py \
#   --audio-root /mnt/8TB_2025/fileserver/audio \
#   --fast-copy \
#   --merge \
#   --model large-v3 || echo "‚ùå Failed: whisper_audio_chunked.py"

# ./.venv/bin/python3 whisper_audio_chunkedv1.py \ [OLD VERSION]
#   --model medium \
#   --merge \
#   --audio-root /mnt/8TB_2025/fileserver/audio \
#   --transcriptions-root /mnt/8TB_2025/fileserver/audio/transcriptions

# ./.venv/bin/python3 whisper_audio_chunked.py \
#   --model medium \
#   --merge \
#   --audio-root /mnt/8TB_2025/fileserver/audio \
#   --transcriptions-root /mnt/8TB_2025/fileserver/audio \
#   --chunks-root /tmp/chunks \
#   --pcm-wav \
#   --chunk-len 90 --stride 85 \
#   --delete-chunks-after \
#   --log-level INFO  || echo "‚ùå Failed: whisper_audio_chunked.py"

DO_TRANSCRIBE=1               # 0 to skip transcription
WHISPER_MODEL=medium            # tiny|base|small|medium|large
WHISPER_LANG=en
echo "‚ñ∂Ô∏è Speaker diarization (dashcam videos + standalone audio)"
./.venv/bin/python3 speakers.py || echo "‚ùå Failed: speakers.py"

# OLD 
# echo "‚ñ∂Ô∏è Ingest (transcripts + RTTM ‚Üí Neo4j)"
# ./.venv/bin/python3 ingest_transcriptions.py || echo "‚ùå Failed: ingest_transcriptions.py"

echo "‚ñ∂Ô∏è Ingest (transcripts + RTTM ‚Üí Neo4j)"
./.venv/bin/python3 ingest_transcriptsv5.py \
  --batch-size 100 \
  --transcript-emb-v2 || echo "‚ùå Failed: ingest_transcripts.py"


echo "‚ñ∂Ô∏è Ingest speakers_reconcile (transcripts + RTTM ‚Üí Neo4j)"
./.venv/bin/python3 speakers_reconcile.py \
  --neo4j-uri bolt://localhost:7687 \
  --neo4j-user neo4j \
  --neo4j-password livelongandprosper \
  --db neo4j \
  --batch 50 \
  --only-missing \
  --allow-discovery  || echo "‚ùå Failed: speakers_reconcile.py"

# Now the rest of your vision/metadata pipeline‚Äîthese do NOT need to precede ingest
echo "‚ñ∂Ô∏è YOLO vehicle detection"
./.venv/bin/python3 yolo_vehicle_detction.py || echo "‚ùå Failed: yolo_vehicle_detction.py"

echo "‚ñ∂Ô∏è Dashcam HUD metadata"
./.venv/bin/python3 metadata_scraper_iterator.py || echo "‚ùå Failed: metadata_scraper_iterator.py"
# ./.venv/bin/python3 dashcam_hud_iterate.py --base /mnt/8TB_2025/fileserver/dashcam || echo "‚ùå Failed: dashcam_hud_iterator.py"
# ./.venv/bin/python3 dashcam_hud_iterate.py --base /mnt/8TBHDD/fileserver/dashcam || echo "‚ùå Failed: dashcam_hud_iterator.py"

echo "‚ñ∂Ô∏è Music precompute + lyrics classifier (optional)"
./.venv/bin/python3 01_precompute_music_segments.py --push-neo4j || echo "‚ùå Failed: 01_precompute_music_segments.py"
./.venv/bin/python3 02_classify_lyrics.py --segments-source neo4j --limit 50000 --model roberta-large-mnli --hf-token "" || echo "‚ùå Failed: 02_classify_lyrics.py"

# === Link local Speakers to GlobalSpeaker identities ===
echo "üîó Linking speakers globally‚Ä¶"
python3 link_global_speakers.py \
  --speaker-batch 900 --items-per-speaker 32 \
  --global-prefilter --global-k 8 --global-m 20 --global-ef 64 \
  --skip-already-linked \
  --source-level auto \
  --min-seg 0.6 --max-snips 8 --max-per-file 3 --snip-len 1.6 \
  --min-proportion 0.4 --min-rms 0.004 --min-snr-db 5.0 \
  --thresh 0.68 \
  --holdout --holdout-min 0.58 --holdout-action drop-members \
  --quarantine-min 0.72 \
  --priority-name "Scott|Kipnerter|Kipnerter Scott" --priority-thresh 0.82 \
  --priority-max-attach 2000 \
  --rank-and-label \
  --audio-cache ./audio_path_cache.json --emb-cache ./emb_cache.sqlite

# ./.venv/bin/python3 link_global_speakers.py \
#   --global-prefilter \
#   --global-thresh 0.74 --global-k 8 --global-index hnsw --global-m 24 --global-ef 128 \
#   --global-include-tentative \
#   --skip-already-linked \
#   --faiss-prefilter --faiss-k 128 --faiss-index hnsw --faiss-m 48 --faiss-ef 256 \
#   --source-level auto \
#   --min-seg 0.6 --max-snips 12 --max-per-file 4 --snip-len 2.0 \
#   --min-proportion 0.4 --min-rms 0.004 --min-snr-db 5.0 \
#   --thresh 0.68 \
#   --holdout --holdout-min 0.58 --holdout-action drop-members \
#   --quarantine-min 0.72 \
#   --priority-name "Scott|Kipnerter|Kipnerter Scott" \
#   --priority-thresh 0.82 \
#   --priority-max-attach 2000 \
#   --rank-and-label \
#   --audio-cache ./audio_path_cache.json \
#   --emb-cache ./emb_cache.sqlite || echo "‚ùå Failed: link_global_speakers.py"

# Less agressive version
# ./.venv/bin/python3 link_global_speakers old.py \
#   --global-prefilter --global-thresh 0.78 --global-k 8 --global-index hnsw --global-m 32 --global-ef 128 \
#   --skip-already-linked \
#   --faiss-prefilter --faiss-k 64 --faiss-index hnsw --faiss-m 32 --faiss-ef 128 \
#   --source-level auto \
#   --min-seg 0.7 --max-snips 8 --max-per-file 3 --snip-len 1.6 \
#   --min-proportion 0.5 --min-rms 0.005 --min-snr-db 6.0 \
#   --thresh 0.72 \
#   --holdout --holdout-min 0.62 --holdout-action drop-members \
#   --audio-cache ./audio_path_cache.json \
#   --emb-cache ./emb_cache.sqlite || echo "‚ùå Failed: link_global_speakers.py"

# OLD
# ./.venv/bin/python3 link_global_speakers.py \
#   --min-seg 0.7 \
#   --max-snips 8 \
#   --max-per-file 3 \
#   --snip-len 1.6 \
#   --min-proportion 0.5 \
#   --min-rms 0.005 \
#   --min-snr-db 6.0 \
#   --thresh 0.72 \
#   --holdout --holdout-min 0.62 --holdout-action drop-members \
#   --audio-cache ./audio_path_cache.json \
#   --emb-cache ./emb_cache.sqlite || echo "‚ùå Failed: link_global_speakers.py"

# echo "üîó Linking speakers globally‚Ä¶" OLD BUT STILL MIGHT WORK NEEVER TESTED PROPERLY
# ./.venv/bin/python3 speaker_linker.py \
#   --min-utt 0.7 \
#   --max-snips 8 \
#   --pad 0.25 \
#   --thresh 0.74 2> /dev/null || echo "‚ùå Failed: dashcam_yolo_embeddings.py"

# echo "‚ñ∂Ô∏è YOLO heatmaps"
# ./.venv/bin/python3 yolo_heatmap_iterator.py || echo "‚ùå Failed: yolo_heatmap_iterator.py"

echo "‚ñ∂Ô∏è Dashcam YOLO embeddings"
./.venv/bin/python3 dashcam_yolo_embeddings.py \
  --resume \
  --grid 16x9 \
  --pyramid \
  --heatmap \
  --repair-missing-moov \
  --neo4j-uri bolt://localhost:7687 \
  --neo4j-user neo4j \
  --neo4j-pass livelongandprosper \
  --win-mins 10 2> /dev/null || echo "‚ùå Failed: dashcam_yolo_embeddings.py"

echo "‚ñ∂Ô∏è Patch Missing Locations in YOLO Embeddings"
./.venv/bin/python3 patch_missing_locations.py \
  --neo4j-uri bolt://localhost:7687 \
  --neo4j-user neo4j \
  --neo4j-pass livelongandprosper \
  --key-limit 1000 \
  --win-mins 10 \
  --validate-m 50 \
  --tx-timeout 45 \
  --max-retries 5 \
  --chunk 500


# echo "‚ñ∂Ô∏è Dashcam Merger" (Not working yet)
# ./.venv/bin/python3 dashcam_merge_FR.py \
#   --base /mnt/8TBHDD/fileserver/dashcam \
#   --base /mnt/8TB_2025/fileserver/dashcam  || echo "‚ùå Failed: dashcam_merge_FR.py"

echo "‚ñ∂Ô∏è Iterator" # (OLD)
./.venv/bin/python3 iterator.py || echo "‚ùå Failed: iterator.py"

echo "‚ñ∂Ô∏è ingest_sidecar_summaries.py"
./.venv/bin/python3 ingest_sidecar_summaries.py \
  --roots /mnt/8TB_2025/fileserver/audio \
  --ensure-schema \
  --create-missing-transcriptions

OLLAMA_MODEL=gemma2:2b OLLAMA_USE_CLI=1 OLLAMA_TIMEOUT=900 python summarize_from_segments_v2.py --all-missing --write-notes --include-utterances

echo "‚ñ∂Ô∏è timelapse_from_fr"
./.venv/bin/python3 timelapse_from_fr.py /mnt/8TB_2025/fileserver/dashcam --recursive || echo "‚ùå Failed: timelapse_from_fr.py"

echo "‚ñ∂Ô∏è timelapse_from_fr"
./.venv/bin/python3 shorts_builder.py --base /mnt/8TB_2025/fileserver/dashcam --profiles clean karaoke wordgrid || echo "‚ùå Failed: shorts_builder.py"

# echo "‚ñ∂Ô∏è timelapse_from_fr"
# ./.venv/bin/python3 shorts_builder.py \
#   --base /mnt/8TB_2025/fileserver/dashcam \
#   --profiles-file profiles.json \
#   --profiles clean karaoke pop_neon cinematic minimal_lower_third meme_bold highlighter tech_hud wordgrid emoji_style || echo "‚ùå Failed: shorts_builder.py"

echo "‚úÖ All scripts finished (some may have failed)."  



# === Link local Speakers to GlobalSpeaker identities ===
# More agressive clustering using pyannote 
# echo "üîó Linking speakers globally‚Ä¶"
# ./.venv/bin/python3 link_global_speakers.py \
#   --backend pyannote \
#   --thresh 0.68 \
#   --holdout --holdout-min 0.62 --holdout-action drop-members